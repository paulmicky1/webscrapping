{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58f226a",
   "metadata": {},
   "source": [
    "# Web Scraping Basics with HTML and BeautifulSoup\n",
    "\n",
    "Use this notebook to learn how we move from a raw HTML page to the information we care about. Each step shows one idea at a time so you can practice as you read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b207a",
   "metadata": {},
   "source": [
    "## Important Guidelines for Web Scraping\n",
    "\n",
    "Keep these habits whenever you scrape a site:\n",
    "\n",
    "1. Check the terms of service and the `robots.txt` file. Only scrape what is allowed.\n",
    "2. Space out your requests. A short delay keeps the site responsive for everyone.\n",
    "3. Re-run your code often. Sites change layouts, so your selectors may need updates.\n",
    "\n",
    "### Example: Checking robots.txt\n",
    "\n",
    "A quick look at `robots.txt` tells us which sections of the site welcome bots and which ones do not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90355514",
   "metadata": {},
   "source": [
    "\n",
    "## What is robots.txt?\n",
    "`robots.txt` is a plain text file located at the root of a website `(e.g., https://example.com/robots.txt)`. It tells web crawlers which parts of the site they can or cannot access.\n",
    "\n",
    "robtots.txt example:\n",
    "```\n",
    "Disallow: /admin/\n",
    "Disallow: /private/\n",
    "Allow: /private/public-info/\n",
    "Crawl-delay: 5\n",
    "Sitemap: https://example.com/sitemap.xml\n",
    "```\n",
    "## What is sitemap.xml?\n",
    "`sitemap.xml` is an XML file that lists URLs on a website that are available for crawling. It helps search engines index content more efficiently.\n",
    "\n",
    "sitemap.xml example:\n",
    "```\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n",
    "  <url>\n",
    "    <loc>https://example.com/</loc>\n",
    "    <lastmod>2025-10-01</lastmod>\n",
    "    <changefreq>weekly</changefreq>\n",
    "    <priority>1.0</priority>\n",
    "  </url>\n",
    "  <url>\n",
    "    <loc>https://example.com/blog/</loc>\n",
    "    <lastmod>2025-10-15</lastmod>\n",
    "    <changefreq>weekly</changefreq>\n",
    "    <priority>0.8</priority>\n",
    "  </url>\n",
    "  <url>\n",
    "    <loc>https://example.com/private/public-info/</loc>\n",
    "    <lastmod>2025-09-30</lastmod>\n",
    "    <changefreq>monthly</changefreq>\n",
    "    <priority>0.5</priority>\n",
    "  </url>\n",
    "</urlset>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ced58f",
   "metadata": {},
   "source": [
    "### Why look at robots.txt?\n",
    "\n",
    "The file explains what each bot can do. A quick checklist:\n",
    "\n",
    "- Open `https://example.com/robots.txt` in a browser.\n",
    "- Sections under `User-agent: *` apply to most scrapers.\n",
    "- `Disallow` lines list paths you must skip; `Allow` lines give explicit approval.\n",
    "- Some sites have extra rules in their terms of service—follow those too.\n",
    "\n",
    "Even when a path is allowed, send requests gently so you do not overload the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120beef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Fetch robots.txt to review allowed paths before scraping\n",
    "url = 'https://www.esilv.fr/robots.txt'\n",
    "response = requests.get(url)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e16206",
   "metadata": {},
   "source": [
    "## Installing and Importing Libraries\n",
    "\n",
    "We rely on three core libraries throughout the course:\n",
    "\n",
    "- `requests` handles HTTP calls.\n",
    "- `beautifulsoup4` (imported as `bs4`) parses the HTML.\n",
    "- `lxml` gives BeautifulSoup a fast parser backend.\n",
    "\n",
    "Install them with any package manager you prefer:\n",
    "\n",
    "**pip**\n",
    "```\n",
    "pip install requests beautifulsoup4 lxml\n",
    "```\n",
    "\n",
    "**conda**\n",
    "```\n",
    "conda install requests beautifulsoup4 lxml\n",
    "```\n",
    "\n",
    "**uv**\n",
    "```\n",
    "uv add requests beautifulsoup4 lxml\n",
    "```\n",
    "\n",
    "Once installed, import them as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BeautifulSoup and requests for the upcoming examples\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8152ac",
   "metadata": {},
   "source": [
    "## Our Sample HTML Page\n",
    "\n",
    "To practice without hitting external sites we use a self-contained HTML snippet. It includes headings, paragraphs, lists, links, a table, and a footer so we can try different selectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fbe1469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample HTML loaded.\n"
     ]
    }
   ],
   "source": [
    "# Local HTML fixture used for all parsing demos below\n",
    "sample_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <title>Sample Web Scraping Page</title>\n",
    "    <style>\n",
    "        .highlight { color: blue; font-weight: bold; }\n",
    "        #main-title { font-size: 24px; color: green; }\n",
    "        table { border-collapse: collapse; }\n",
    "        th, td { border: 1px solid black; padding: 5px; }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1 id=\"main-title\">Welcome to Web Scraping</h1>\n",
    "    <h2>Introduction</h2>\n",
    "    <p class=\"intro\">This is an introductory paragraph.</p>\n",
    "    <p class=\"intro highlight\">Another intro paragraph with <b>bold text</b>.</p>\n",
    "    <p class=\"content\">Content paragraph.</p>\n",
    "\n",
    "    <h2>Libraries</h2>\n",
    "    <p>Useful libraries for web scraping:</p>\n",
    "    <ul>\n",
    "        <li><a href=\"https://beautiful-soup-4.readthedocs.io/\" class=\"library\" id=\"link1\">BeautifulSoup</a></li>\n",
    "        <li><a href=\"https://docs.scrapy.org/\" class=\"library\" id=\"link2\">Scrapy</a></li>\n",
    "        <li><a href=\"https://selenium-python.readthedocs.io/\" class=\"library\" id=\"link3\">Selenium</a></li>\n",
    "    </ul>\n",
    "\n",
    "    <h2>Data Table</h2>\n",
    "    <table>\n",
    "        <tr><th>Library</th><th>Purpose</th></tr>\n",
    "        <tr><td>BeautifulSoup</td><td>HTML Parsing</td></tr>\n",
    "        <tr><td>Requests</td><td>HTTP Requests</td></tr>\n",
    "    </table>\n",
    "\n",
    "    <div class=\"footer\">\n",
    "        <p>Footer text.</p>\n",
    "        <!-- This is a comment -->\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sample HTML loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc454cb",
   "metadata": {},
   "source": [
    "### Creating the Soup Object\n",
    "\n",
    "BeautifulSoup turns raw HTML into a searchable tree. Build the soup once and reuse it across the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML string and view the formatted structure\n",
    "soup = BeautifulSoup(sample_html, 'lxml') # html.parser can also be used\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccad6a0",
   "metadata": {},
   "source": [
    "## What is HTML?\n",
    "\n",
    "HTML (HyperText Markup Language) gives structure to every web page. Key pieces you will see often:\n",
    "\n",
    "- `<!DOCTYPE html>` announces an HTML document.\n",
    "- `<html>` wraps the full page.\n",
    "- `<head>` stores metadata, the title, and CSS rules.\n",
    "- `<body>` contains the visible content.\n",
    "- Headings (`<h1>` … `<h6>`), paragraphs (`<p>`), and links (`<a>`) show the text.\n",
    "- Lists use `<ul>` / `<ol>` with `<li>` items.\n",
    "- Tables use rows `<tr>`, headers `<th>`, and cells `<td>`.\n",
    "- `<div>` groups related content.\n",
    "- Inline styles and comments sit inside the HTML as well.\n",
    "\n",
    "Attributes such as `id`, `class`, and `href` help us target the right elements while scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b16e80",
   "metadata": {},
   "source": [
    "## What is CSS?\n",
    "\n",
    "CSS (Cascading Style Sheets) styles the HTML. Two attributes appear everywhere:\n",
    "\n",
    "- `id` labels a single element.\n",
    "- `class` groups elements that share a style.\n",
    "\n",
    "Scrapers reuse these same identifiers to find the content we need within the page structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12ae38",
   "metadata": {},
   "source": [
    "### Selecting Elements by id and class\n",
    "\n",
    "BeautifulSoup exposes simple helpers:\n",
    "\n",
    "- `soup.find(id=\"main-title\")` grabs the unique element with that id.\n",
    "- `soup.select(\".intro\")` returns every element that carries the `intro` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dbf21e",
   "metadata": {},
   "source": [
    "### Finding Elements by Class\n",
    "\n",
    "Use either approach depending on what feels clearer:\n",
    "\n",
    "- `soup.find(class_=\"intro\")` returns the first match.\n",
    "- `soup.select(\".intro\")` returns a list of matches for looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb09691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the element with the unique 'id'\n",
    "title = soup.find(id=\"main-title\")\n",
    "print(\"Title:\", title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect every paragraph that uses the intro class\n",
    "intros = soup.select(\".intro\")\n",
    "print(\"Intro paragraphs:\")\n",
    "for p in intros:\n",
    "    print(p.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b6e29",
   "metadata": {},
   "source": [
    "### Finding Elements by Class (Alternative)\n",
    "\n",
    "The `class_` keyword works when you only need the first match and want a shorter syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First .find() match for the content class\n",
    "content = soup.find(class_=\"content\")\n",
    "print(\"Content:\", content.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5dc83",
   "metadata": {},
   "source": [
    "## Working with the Sample Page\n",
    "\n",
    "From here on we reuse the `sample_html` content. Each section shows a new way to pull information from the same structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e31fa",
   "metadata": {},
   "source": [
    "## Basics of the Title Tag\n",
    "\n",
    "Title information helps identify the page quickly. We can examine the tag, the text inside it, and its position in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d53faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the raw <title> tag\n",
    "print(\"Title tag:\", soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc3ecf",
   "metadata": {},
   "source": [
    "### Read the Title Text\n",
    "\n",
    "`.text` strips away the tag and leaves the readable string—perfect for logging or saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull just the text inside the <title> tag\n",
    "print(\"Title text:\", soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5567a30",
   "metadata": {},
   "source": [
    "### Check the Tag Name\n",
    "\n",
    "`.name` confirms the element type so you can branch logic when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5daff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the element type\n",
    "print(\"Tag name:\", soup.title.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930fda8",
   "metadata": {},
   "source": [
    "### Look at the Parent\n",
    "\n",
    "`.parent` steps one level up the tree so you can inspect the surrounding structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move up one level to see where the paragraph lives\n",
    "print(\"Parent:\", soup.p.parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8329947",
   "metadata": {},
   "source": [
    "## Basics of Paragraph Tags\n",
    "\n",
    "Paragraphs (`<p>`) often hold the text you want. We can grab the first one, inspect its classes, and loop through all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First paragraph element in the document\n",
    "print(\"First p:\", soup.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1712cf3",
   "metadata": {},
   "source": [
    "### Check the Paragraph Classes\n",
    "\n",
    "Access the `class` attribute to see how the page labels each paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the class list attached to that paragraph\n",
    "print(\"Class:\", soup.p['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b493f3",
   "metadata": {},
   "source": [
    "### Read the Paragraph Text\n",
    "\n",
    "`.text` provides the cleaned text content, ready for storage or further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5bc352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract plain text from the paragraph\n",
    "print(\"Text:\", soup.p.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a394ff6",
   "metadata": {},
   "source": [
    "### Loop Through All Paragraphs\n",
    "\n",
    "`find_all('p')` returns every paragraph tag so you can iterate and handle them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535fb553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather every <p> element and inspect the text\n",
    "all_p = soup.find_all('p')\n",
    "print(\"Number of p tags:\", len(all_p))\n",
    "\n",
    "for i, p in enumerate(all_p):\n",
    "    print(f\"P {i+1}: {p.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce853892",
   "metadata": {},
   "source": [
    "## Basics of Anchor Tags\n",
    "\n",
    "Links (`<a>`) contain two important pieces: the clickable text and the `href` that points to the destination. They can also carry classes and ids for styling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c057632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First anchor element in the document\n",
    "print(\"First a:\", soup.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d5c31",
   "metadata": {},
   "source": [
    "### Read the Href Attribute\n",
    "\n",
    "`href` stores the actual link target. We often capture it alongside the anchor text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004362c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the destination URL from the link\n",
    "print(\"Href:\", soup.a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf234f",
   "metadata": {},
   "source": [
    "### Check Class and ID Attributes\n",
    "\n",
    "Classes group similar links; an id marks one specific link. Both are useful for targeting elements precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f679d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the label information attached to the link\n",
    "print(\"Class:\", soup.a['class'])\n",
    "print(\"Id:\", soup.a['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca3838",
   "metadata": {},
   "source": [
    "### List Every Link\n",
    "\n",
    "Looping through `find_all('a')` gives us every anchor. Store or print each `href` depending on your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ab37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each <a> tag and print the target URL\n",
    "all_a = soup.find_all('a')\n",
    "print(\"All hrefs:\")\n",
    "for a in all_a:\n",
    "    print(a.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e48b1",
   "metadata": {},
   "source": [
    "## Analyzing the HTML Structure\n",
    "\n",
    "Understanding parents and children helps when the data you need sits near a known element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1527913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk up the tree from a single link\n",
    "link = soup.a\n",
    "print(\"Parents:\")\n",
    "for parent in link.parents:\n",
    "    print(parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0366728",
   "metadata": {},
   "source": [
    "### List Every Tag\n",
    "\n",
    "`recursiveChildGenerator()` walks the entire tree, letting us audit which tag types appear on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all tags present in the document\n",
    "print(\"All tags:\")\n",
    "for child in soup.recursiveChildGenerator():\n",
    "    if child.name:\n",
    "        print(child.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375794a",
   "metadata": {},
   "source": [
    "## Finding Elements by ID\n",
    "\n",
    "An id should appear only once per page, making it a reliable way to select a single element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d64a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the Selenium link by its id\n",
    "link3 = soup.find(id=\"link3\")\n",
    "print(\"Link 3:\", link3.text)\n",
    "print(\"Href:\", link3['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd463b8",
   "metadata": {},
   "source": [
    "## Working with Headers\n",
    "\n",
    "Headers outline the structure of the page. Scraping them provides quick summaries or section navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First h2 element on the page\n",
    "h2 = soup.find('h2')\n",
    "print(\"H2 text:\", h2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa23683",
   "metadata": {},
   "source": [
    "### Collect All Headers\n",
    "\n",
    "Pass a list of tag names to `find_all` to capture multiple heading levels in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c30c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather h1 and h2 text to understand section names\n",
    "headers = soup.find_all([\"h1\", \"h2\"])\n",
    "for h in headers:\n",
    "    print(f\"{h.name}: {h.text.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b3d069",
   "metadata": {},
   "source": [
    "## Extracting All URLs\n",
    "\n",
    "Every `<a>` tag carries an `href`. Printing them now makes it easy to decide which pages to visit next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each hyperlink so we can inspect or queue them\n",
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1614f3ac",
   "metadata": {},
   "source": [
    "## Getting All Text\n",
    "\n",
    "`get_text()` removes every tag and returns the readable page content. It is handy for quick text exports or keyword searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump all visible text from the page\n",
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e809f",
   "metadata": {},
   "source": [
    "## Working with Strings and Comments\n",
    "\n",
    "BeautifulSoup treats text inside tags as `NavigableString` objects and HTML comments as a related type. You can read or replace them just like regular strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings inside tags behave like standard Python strings\n",
    "soup_string = BeautifulSoup('<b class=\"type\">Web Scraper</b>', 'html.parser')\n",
    "tag = soup_string.b\n",
    "print(\"String:\", tag.string)\n",
    "print(\"Type:\", type(tag.string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a74c4",
   "metadata": {},
   "source": [
    "### Replacing Text Inside Tags\n",
    "\n",
    "Use `replace_with()` when you need to update the content while keeping the tag in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6750de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the existing text for a friendlier message\n",
    "tag.string.replace_with(\"Good web scraper\")\n",
    "print(\"After replace:\", tag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72687b0d",
   "metadata": {},
   "source": [
    "### Handling Comments\n",
    "\n",
    "HTML comments are stored as a special string subclass. You can read them to see hidden notes or replace them if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments appear as Comment objects when parsed\n",
    "markup = \"<b><!--Hey, I wish to be a good web scraper--></b>\"\n",
    "soup_comment = BeautifulSoup(markup, 'html.parser')\n",
    "comment = soup_comment.b.string\n",
    "print(\"Comment:\", comment)\n",
    "print(\"Type:\", type(comment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b1e47",
   "metadata": {},
   "source": [
    "## Navigating Siblings\n",
    "\n",
    "Use `next_sibling` and `previous_sibling` to move sideways between elements that share the same parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move from <b> to its sibling <c>\n",
    "sibling_soup = BeautifulSoup(\"<a><b>text1</b><c>text2</c></a>\", 'html.parser')\n",
    "print(\"Next sibling of b:\", sibling_soup.b.next_sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10c2df",
   "metadata": {},
   "source": [
    "### Navigate Backward\n",
    "\n",
    "`previous_sibling` walks in the opposite direction when you need the element that comes before the current one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go from <c> back to its <b> sibling\n",
    "print(\"Previous sibling of c:\", sibling_soup.c.previous_sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c253dd4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You now have the core tools to parse HTML with BeautifulSoup:\n",
    "\n",
    "- Respect site rules (`robots.txt`) and pace your requests.\n",
    "- Inspect the HTML structure to choose the right selectors.\n",
    "- Use BeautifulSoup to locate tags, attributes, and text.\n",
    "- Traverse the tree when information sits near the elements you already know.\n",
    "\n",
    "Practice these moves on real pages and adapt your selectors as layouts change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44881e-1c90-4269-8d93-fe2f872f8670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
